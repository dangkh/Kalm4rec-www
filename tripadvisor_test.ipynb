{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf65e7a-8462-477f-884f-428aa97d690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\dangkh\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from ast import parse\n",
    "import os\n",
    "import time\n",
    "from retrievalHelper.utils import *\n",
    "from kwExtractorHelper.utils import mkdir\n",
    "from retrievalHelper.u4Res import *\n",
    "from retrievalHelper.u4KNN import *\n",
    "from retrievalHelper.u4train import *\n",
    "from retrievalHelper.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "febde23b-8e51-4f1a-bcf9-676ebdc5abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1001\n",
    "setSeed(random_seed)\n",
    "\n",
    "listcity = ['charlotte', 'edinburgh', 'lasvegas', 'london', 'phoenix', 'pittsburgh', 'singapore']\n",
    "city = \"tripAdvisor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8510f2cf-be73-47b9-8402-f6728c63434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info from extracted file\n",
      "Number of keyword: 49928\n",
      "info from extracted file\n",
      "Number of keyword: 125955\n"
     ]
    }
   ],
   "source": [
    "trainDat, testDat = data_reviewLoader(city)\n",
    "train_users, train_users2kw = extract_users(trainDat['np2users'])\n",
    "test_users, test_users2kw = extract_users(testDat['np2users'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc549c52-9f5e-43dd-9f41-24e1ca35930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeType = \"IUF\"\n",
    "quantity = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854d4d13-057a-4949-9d78-90089b97a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of review:  84904\n"
     ]
    }
   ],
   "source": [
    "gt = load_groundTruth(f'./data/reviews/{city}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d508b04d-e103-4897-86d3-a6364a2ee572",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordScore, keywordFrequence = load_kwScore(city, edgeType)\n",
    "restGraph = retaurantReviewG([trainDat, keywordScore, keywordFrequence, \\\n",
    "                                quantity,  edgeType, gt])\n",
    "\n",
    "KNN = neighbor4kw(f'{city}_kwSenEB_pad', testDat,  restGraph)\n",
    "rest_Label = getRestLB(trainDat['np2rests'])\n",
    "\n",
    "prediction = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b5743-4642-44e7-ad00-de07943808e6",
   "metadata": {},
   "source": [
    "# JACCARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150aaaa7-d59f-457a-b879-189caecf7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*50)\n",
    "print(\"using Jaccard\")\n",
    "print(\"*\"*50)\n",
    "jcsim = JaccardSim(f'./data/score/{city}-keywords-TFIUF.json', quantity)\n",
    "lResults = []\n",
    "for idx in tqdm(range(len(test_users))):\n",
    "    testUser = test_users[idx]\n",
    "    testkey = test_users2kw[idx]\n",
    "    pred = jcsim.pred(testkey)\n",
    "    groundtruth = gt[testUser]\n",
    "    prediction.append(pred)\n",
    "    score = quick_eval(pred, groundtruth, sourceFile, city=='tripAdvisor')\n",
    "    lResults.append(score)\n",
    "mp, mr, mf = extractResult(lResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013e536-6e27-423a-9268-bc5b5407cbbc",
   "metadata": {},
   "source": [
    "# MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9562abd2-904e-40e4-81c4-999b90a52e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "running MF-BPR at: \n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9499/9499 [00:00<00:00, 10000.91it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2394/2394 [00:00<00:00, 9564.51it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*50)\n",
    "print(\"running MF-BPR at: \")\n",
    "print(\"*\"*50)\n",
    "\n",
    "numUser = len(train_users)\n",
    "numItem = len(rest_Label)\n",
    "\n",
    "label_train, label_test = label_ftColab(train_users, test_users, gt, restGraph.numRest, rest_Label)\n",
    "\n",
    "learning_rate = 0.03\n",
    "embedding_dim = 32\n",
    "num_epochs = 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538b472e-40fa-4f63-8ebb-f8056a74205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLB = np.asarray(label_train)\n",
    "testLB = np.asarray(label_test)\n",
    "train_dataset = DataBPR(trainLB)\n",
    "test_dataset = DataBPR(trainLB, True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaf840e7-17a6-49b0-8611-bd4b8c82203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFBPR(\n",
      "  (embed_user): Embedding(9499, 32)\n",
      "  (embed_item): Embedding(3097, 32)\n",
      ")\n",
      "Epoch [1/30], Loss: 58735.69380950928\n",
      "Epoch [2/30], Loss: 13745.461366653442\n",
      "Epoch [3/30], Loss: 1408.0112488865852\n",
      "Epoch [4/30], Loss: 138.45384038984776\n",
      "Epoch [5/30], Loss: 39.52012599632144\n",
      "Epoch [6/30], Loss: 25.013183349743485\n",
      "Epoch [7/30], Loss: 18.873755887150764\n",
      "Epoch [8/30], Loss: 14.65679629612714\n",
      "Epoch [9/30], Loss: 11.49552525114268\n",
      "Epoch [10/30], Loss: 9.065094801597297\n",
      "Epoch [10/30], prec: 0.06402865711429524, rec: 0.1812733477164979, f1: 0.09131161103207273\n",
      "Epoch [11/30], Loss: 7.164304377511144\n",
      "Epoch [12/30], Loss: 5.665467691142112\n",
      "Epoch [13/30], Loss: 4.479306990280747\n",
      "Epoch [14/30], Loss: 3.535994851961732\n",
      "Epoch [15/30], Loss: 2.78547325078398\n",
      "Epoch [16/30], Loss: 2.190803668112494\n",
      "Epoch [17/30], Loss: 1.7198301464086398\n",
      "Epoch [18/30], Loss: 1.3474361373810098\n",
      "Epoch [19/30], Loss: 1.0533685258124024\n",
      "Epoch [20/30], Loss: 0.822283276123926\n",
      "Epoch [20/30], prec: 0.06976007997334223, rec: 0.1984105275139239, f1: 0.09964267528503404\n",
      "Epoch [21/30], Loss: 0.6405625854968093\n",
      "Epoch [22/30], Loss: 0.4983159726834856\n",
      "Epoch [23/30], Loss: 0.3870331961661577\n",
      "Epoch [24/30], Loss: 0.3002921941515524\n",
      "Epoch [25/30], Loss: 0.23263203926035203\n",
      "Epoch [26/30], Loss: 0.18007561368722236\n",
      "Epoch [27/30], Loss: 0.1392014967132127\n",
      "Epoch [28/30], Loss: 0.10758085818815744\n",
      "Epoch [29/30], Loss: 0.08306765271117911\n",
      "Epoch [30/30], Loss: 0.06410283727018395\n",
      "Epoch [30/30], prec: 0.0737087637454182, rec: 0.21101660608926304, f1: 0.10549870671688621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2394 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m3000\u001b[39m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m testUser, topK_Key, topUser \u001b[38;5;241m=\u001b[39m procesTest(test_users, test_users2kw, idx, KNN, restGraph, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m idU \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor([train_users\u001b[38;5;241m.\u001b[39mindex(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m topUser])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     40\u001b[0m rest_score \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "model = MFBPR(numUser, numItem, embedding_dim).to(device)\n",
    "\n",
    "mp, mr, mf = 0, 0, 0\n",
    "print(model)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay= 1e-4)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_idx, batchDat in enumerate(train_loader):\n",
    "        uid, pid, nid = batchDat\n",
    "        uid = uid.to(device)\n",
    "        pid = pid.to(device)\n",
    "        nid = nid.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_i, pred_j = model(uid, pid, nid)\n",
    "        loss = - ((pred_i - pred_j).sigmoid()+1e-10).log().sum()\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() \n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss}')\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        \n",
    "        lResults = evaluateModel_MFBPR(model, test_loader, \"\", gt, train_users, quantity, rest_Label)\n",
    "        p, r, f = extractResult(lResults)\n",
    "        if mean(r) > mean(mr):\n",
    "            mp, mr, mf = p, r, f\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], prec: {mean(p)}, rec: {mean(r)}, f1: {mean(f)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080c850-96b6-4bf6-93cd-af418b93b359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                            | 46/2394 [02:04<1:46:15,  2.72s/it]"
     ]
    }
   ],
   "source": [
    "lResults = []\n",
    "for idx in tqdm(range(len(test_users))):\n",
    "    if idx > 3000:\n",
    "        break\n",
    "    testUser, topK_Key, _, topUser = procesTest(test_users, test_users2kw, idx, KNN, restGraph, True)\n",
    "    idU = torch.LongTensor([train_users.index(x) for x in topUser]).to(device)\n",
    "    rest_score = []\n",
    "    for rest in range(restGraph.numRest):\n",
    "        restID = torch.LongTensor([rest]).to(device)\n",
    "        rest_score.append(model.csPrediction(idU,restID))\n",
    "    \n",
    "    tmp = np.argsort(rest_score)[::-1][:20]\n",
    "    restPred = [rest_Label[x] for x in tmp]\n",
    "\n",
    "    groundtruth = gt[testUser]\n",
    "    score = quick_eval(restPred, groundtruth, None, city=='tripAdvisor')\n",
    "    lResults.append(score)\n",
    "mp, mr, mf = extractResult(lResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb6f25-417c-404d-99b3-674e6435d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, f = mp, mr, mf \n",
    "print(mean(p), mean(r), mean(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d0afd-77af-4427-bda5-25dfd524e9ae",
   "metadata": {},
   "source": [
    "# MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdfd8574-b228-4e29-bf1f-131a734f2023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "using MPG\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3097/3097 [01:27<00:00, 35.20it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*50)\n",
    "print(\"using MPG\")\n",
    "print(\"*\"*50)\n",
    "l_rest = restGraph.listRestCode\n",
    "kw_data = KNN.kw_data\n",
    "lu, li, lh = list([]), list([]), list([])\n",
    "for rest in tqdm(keywordScore):\n",
    "    kw_scs = keywordScore[rest]\n",
    "    u = l_rest.index(rest)\n",
    "    tmpI, tmpH = [], []\n",
    "    for kw, sc in kw_scs:\n",
    "        tmpI.append(kw_data.index(kw))\n",
    "        tmpH.append(sc)\n",
    "    tmpU = [u] * len(tmpI)\n",
    "    lu.extend(tmpU)\n",
    "    li.extend(tmpI)\n",
    "    lh.extend(tmpH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d013dc65-1f88-49d6-9110-3d4c1132e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.zeros([len(l_rest), len(kw_data)])\n",
    "for ii in range(len(lu)):\n",
    "    u, v, w = lu[ii], li[ii], lh[ii]\n",
    "    adj[u, v] = w\n",
    "\n",
    "lResults = []\n",
    "lidx = [x for x in range(len(test_users))]\n",
    "np.random.shuffle(lidx)\n",
    "dictionary = {}\n",
    "listsimU = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "965772d9-0958-4a14-a69e-034aadfb6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_eval2(preds, gt, source = None):\n",
    "    '''\n",
    "    - preds: [list of restaurants]\n",
    "    - GT: [('wrdLrTcHXlL4UsiYn3cgKQ', 4.0), ('uG59lRC-9fwt64TCUHnuKA', 3.0)]\n",
    "    - \n",
    "    '''\n",
    "    gt_list = set([str(a[0]) for a in gt])\n",
    "    # print(gt_list)\n",
    "    preds_list = list(set(preds))\n",
    "    ov = gt_list.intersection(preds_list)\n",
    "    # print(\"*\"*20)\n",
    "    # print(ov)\n",
    "    # print(\"*\"*20)\n",
    "    prec = len(ov)/len(preds_list)\n",
    "    rec = len(ov)/len(gt_list)\n",
    "    f1 = 0 if prec+rec == 0 else 2*prec*rec/(prec+rec)\n",
    "    # if source != None :\n",
    "    #     print(\"Precision: {}, Recall: {}, F1: {}\".format(prec, rec, f1), file = source)\n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d92b333c-a947-442e-bb88-1092e0caf203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2394 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['223023', '225108', '87617', '641273', '87638', '223061', '114581', '93618', '220240', '259593', '208455', '84115', '87620', '114595', '87657', '87590', '91042', '87645', '87592', '217498'] [(208455, 5.0), (87656, 3.0), (223061, 4.0), (87659, 4.0), (99535, 5.0), (259593, 5.0)]\n",
      "(0.15, 0.5, 0.23076923076923075)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m score \u001b[38;5;241m=\u001b[39m quick_eval2(result, groundtruth)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mstop\u001b[49m\n\u001b[0;32m     17\u001b[0m lResults\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "for ite in tqdm(range(len(test_users))):\n",
    "    idx = lidx[ite]\n",
    "    testUser, topK_Key, keyfrequency, topUser = procesTest(test_users, test_users2kw, idx, KNN, restGraph, False)\n",
    "    testkey = [kw_data.index(x) for x in topK_Key]\n",
    "    ft = np.zeros(len(kw_data))\n",
    "    for x in testkey: ft[x] = 1.0\n",
    "    ft = ft.reshape(-1, 1)\n",
    "    tmp = np.matmul(adj, ft).reshape(-1)\n",
    "    idxrest = np.argsort(tmp)[::-1]\n",
    "    result = [l_rest[x] for x in idxrest[:quantity]]\n",
    "    prediction.append(result)\n",
    "    groundtruth = gt[testUser]\n",
    "    print(result, groundtruth)\n",
    "    score = quick_eval2(result, groundtruth)\n",
    "    print(score)\n",
    "    stop\n",
    "    lResults.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3fc3a413-a64a-47c6-b26f-4f7aab991ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13180868838763576, 0.3948970000249251, 0.19182999295526143)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp, mr, mf = extractResult(lResults)\n",
    "mean(mp), mean(mr), mean(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f0bf205-0538-48e4-aa44-fb2b89488b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2394 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60763, 35805, 60956, 55711]\n",
      "['223023', '225108', '87617', '87638', '223061', '114581', '93618', '220240', '259593', '208455', '87620', '114595', '87657', '87590', '91042', '87645', '87592', '217498', '111487', '114577'] [(208455, 5.0), (87656, 3.0), (223061, 4.0), (87659, 4.0), (99535, 5.0), (259593, 5.0)]\n",
      "(0.15, 0.5, 0.23076923076923075)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m score \u001b[38;5;241m=\u001b[39m quick_eval2(result, groundtruth)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mstop\u001b[49m\n\u001b[0;32m     19\u001b[0m lResults\u001b[38;5;241m.\u001b[39mappend(score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "for ite in tqdm(range(len(test_users))):\n",
    "    idx = lidx[ite]\n",
    "    testUser, topK_Key, keyfrequency, topUser = procesTest(test_users, test_users2kw, idx, KNN, restGraph, False)\n",
    "    testkey = [kw_data.index(x) for x in topK_Key]\n",
    "    ft = np.zeros(len(kw_data))\n",
    "    for x in testkey: ft[x] = 1.0\n",
    "    ft = ft.reshape(-1, 1)\n",
    "    tmp = np.matmul(adj, ft).reshape(-1)\n",
    "    sc = tmpHelper.query(testUser)\n",
    "    tmp = tmp*sc\n",
    "    idxrest = np.argsort(tmp)[::-1]\n",
    "    result = [l_rest[x] for x in idxrest[:quantity]]\n",
    "    prediction.append(result)\n",
    "    groundtruth = gt[testUser]\n",
    "    print(result, groundtruth)\n",
    "    score = quick_eval2(result, groundtruth)\n",
    "    print(score)\n",
    "    stop\n",
    "    lResults.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3624b4f4-2480-4aee-9d94-615589e8d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13635477582846003, 0.40906758577225427, 0.19852822307281182)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp, mr, mf = extractResult(lResults)\n",
    "mean(mp), mean(mr), mean(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b66b5981-2a10-4dce-bb40-e2214f8aa442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class regionHelper(object):\n",
    "    \"\"\"docstring for regionHelper\"\"\"\n",
    "    def __init__(self):\n",
    "        super(regionHelper, self).__init__()\n",
    "        df2 = pd.read_csv('./data/reviews/hotel.csv')\n",
    "        hotel_region_dict = dict(zip(df2['hotelID'], df2['region_id']))\n",
    "        rest2city = []\n",
    "        for rest in l_rest:\n",
    "            rest = int(rest)\n",
    "            rest2city.append(hotel_region_dict[rest])\n",
    "        self.rest2city = np.asarray(rest2city)\n",
    "        with open('./data/reviews/user2region.json', 'r') as f:\n",
    "            self.author_region = json.load(f)\n",
    "\n",
    "\n",
    "    def query(self, idx):\n",
    "        tmp_reg = self.author_region[str(idx)]\n",
    "        print(tmp_reg)\n",
    "        marker = np.zeros(len(self.rest2city))\n",
    "        for reg in tmp_reg:\n",
    "            tmp = np.where(self.rest2city == reg)[0]\n",
    "            marker[tmp] = 1\n",
    "        return marker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a14e7d7e-0630-4079-bcc1-2296111906eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpHelper = regionHelper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339aad9-3647-44ea-96fa-7a8d324c1f08",
   "metadata": {},
   "source": [
    "# CBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b46ffb8e-9070-405d-ae94-b2297e94ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Using CBR\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "print(\"*\"*50)\n",
    "print(\"Using CBR\")\n",
    "print(\"*\"*50)\n",
    "dim_users, dim_items = 384, 384\n",
    "learning_rate = 0.03\n",
    "hidden_dim = 32\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "277ebdd9-755a-478d-b3dd-7477e7c3a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Using CBR\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9499/9499 [00:00<00:00, 16142.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing CBR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m userFT, userFT_test, rest_feature \u001b[38;5;241m=\u001b[39m \u001b[43mKNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadFT\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrest_Label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m label_train, label_test \u001b[38;5;241m=\u001b[39m label_ftColab(train_users, test_users, gt, restGraph\u001b[38;5;241m.\u001b[39mnumRest, rest_Label)\n\u001b[0;32m      8\u001b[0m dim_users, dim_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m384\u001b[39m\n",
      "File \u001b[1;32mD:\\Dang\\ALM4Res\\retrievalHelper\\u4KNN.py:62\u001b[0m, in \u001b[0;36mneighbor4kw.loadFT\u001b[1;34m(self, numKW4FT, rest_Label, city)\u001b[0m\n\u001b[0;32m     59\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     userKw\u001b[38;5;241m.\u001b[39mappend(topK_Key)\n\u001b[1;32m---> 62\u001b[0m userFT \u001b[38;5;241m=\u001b[39m \u001b[43muserKW2FT\u001b[49m\u001b[43m(\u001b[49m\u001b[43muserKw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwEB_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m userFT \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(userFT)\n\u001b[0;32m     66\u001b[0m restFT \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Dang\\ALM4Res\\retrievalHelper\\utils.py:118\u001b[0m, in \u001b[0;36muserKW2FT\u001b[1;34m(userKw, kwEB_pad, kw_data, sameShape)\u001b[0m\n\u001b[0;32m    116\u001b[0m         em \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(kwEB_pad[kwIdx])\n\u001b[0;32m    117\u001b[0m         userFT\u001b[38;5;241m.\u001b[39mappend(em)\n\u001b[1;32m--> 118\u001b[0m     userFT \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43muserFT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     usersFT\u001b[38;5;241m.\u001b[39mappend(userFT)\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sameShape:\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\dangkh\\lib\\site-packages\\numpy\\core\\shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "userFT, userFT_test, rest_feature = KNN.loadFT(20, rest_Label, city)\n",
    "label_train, label_test = label_ftColab(train_users, test_users, gt, restGraph.numRest, rest_Label)\n",
    "\n",
    "\n",
    "\n",
    "trainLB = np.asarray(label_train)\n",
    "testLB = np.asarray(label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d625f42-7bf6-4cad-a0d7-0d59d5257efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature shape (train / test):\n",
      "(9499, 20, 384) (2394, 20, 384)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mnbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mnbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m rest_feature \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrest_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mFloatTensor)\n\u001b[0;32m     12\u001b[0m rest_feature \u001b[38;5;241m=\u001b[39m rest_feature\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "nbatch_size = 128\n",
    "\n",
    "print(\"feature shape (train / test):\")\n",
    "print(userFT.shape, userFT_test.shape)\n",
    "train_dataset = DataCF(userFT, trainLB)\n",
    "test_dataset = DataCF(userFT_test, testLB)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=nbatch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=nbatch_size, shuffle=False)\n",
    "rest_feature = torch.from_numpy(rest_feature).type(torch.FloatTensor)\n",
    "rest_feature = rest_feature.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2abffd60-faaf-4ec9-a5e8-04ed05399b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBR(dim_users, dim_items, hidden_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "915134d5-aa64-4216-a962-1b660f7b79c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBR(\n",
      "  (user_embeddings): Linear(in_features=384, out_features=32, bias=True)\n",
      "  (uAP): AttentionPooling(\n",
      "    (V): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (w): Linear(in_features=8, out_features=1, bias=True)\n",
      "    (tanh): Sigmoid()\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      "  (item_embeddings): Linear(in_features=384, out_features=32, bias=True)\n",
      "  (iAP): AttentionPooling(\n",
      "    (V): Linear(in_features=32, out_features=8, bias=True)\n",
      "    (w): Linear(in_features=8, out_features=1, bias=True)\n",
      "    (tanh): Sigmoid()\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (activate): Sigmoid()\n",
      ")\n",
      "Epoch [1/500], Loss: 3.1844739066436887\n",
      "Epoch [2/500], Loss: 1.1400064500048757\n",
      "Epoch [3/500], Loss: 1.1156885456293821\n",
      "Epoch [4/500], Loss: 1.0991381723433733\n",
      "Epoch [5/500], Loss: 1.0889850594103336\n",
      "Epoch [6/500], Loss: 1.084524480625987\n",
      "Epoch [7/500], Loss: 1.0812150817364454\n",
      "Epoch [8/500], Loss: 1.0785928899422288\n",
      "Epoch [9/500], Loss: 1.0754112675786018\n",
      "Epoch [10/500], Loss: 1.074268151074648\n",
      "Epoch [10/500], prec: 0.020760233918128656, rec: 0.060588381322547284, f1: 0.029824214132553577\n",
      "Epoch [11/500], Loss: 1.0733827278017998\n",
      "Epoch [12/500], Loss: 1.071590220555663\n",
      "Epoch [13/500], Loss: 1.0710554840043187\n",
      "Epoch [14/500], Loss: 1.067962591536343\n",
      "Epoch [15/500], Loss: 1.0677481517195702\n",
      "Epoch [16/500], Loss: 1.0668127797544003\n",
      "Epoch [17/500], Loss: 1.0660200910642743\n",
      "Epoch [18/500], Loss: 1.0651278160512447\n",
      "Epoch [19/500], Loss: 1.064239488914609\n",
      "Epoch [20/500], Loss: 1.0618003066629171\n",
      "Epoch [20/500], prec: 0.022827903091060985, rec: 0.06671328764205123, f1: 0.03286375254452874\n",
      "Epoch [21/500], Loss: 1.0599320568144321\n",
      "Epoch [22/500], Loss: 1.059281812980771\n",
      "Epoch [23/500], Loss: 1.0553444046527147\n",
      "Epoch [24/500], Loss: 1.054324139840901\n",
      "Epoch [25/500], Loss: 1.0496585927903652\n",
      "Epoch [26/500], Loss: 1.0483425911515951\n",
      "Epoch [27/500], Loss: 1.04394590575248\n",
      "Epoch [28/500], Loss: 1.0426014829427004\n",
      "Epoch [29/500], Loss: 1.0391259947791696\n",
      "Epoch [30/500], Loss: 1.0358634358271956\n",
      "Epoch [30/500], prec: 0.03592314118629908, rec: 0.10541580163527804, f1: 0.05185353941145789\n",
      "Epoch [31/500], Loss: 1.0334061877802014\n",
      "Epoch [32/500], Loss: 1.030843992717564\n",
      "Epoch [33/500], Loss: 1.0271291844546795\n",
      "Epoch [34/500], Loss: 1.025669720955193\n",
      "Epoch [35/500], Loss: 1.0239692721515894\n",
      "Epoch [36/500], Loss: 1.022235200740397\n",
      "Epoch [37/500], Loss: 1.0183441741392016\n",
      "Epoch [38/500], Loss: 1.0183775275945663\n",
      "Epoch [39/500], Loss: 1.0152335222810507\n",
      "Epoch [40/500], Loss: 1.0142895262688398\n",
      "Epoch [40/500], prec: 0.048684210526315795, rec: 0.14535275446316234, f1: 0.0706689182221475\n",
      "Epoch [41/500], Loss: 1.0124356681481004\n",
      "Epoch [42/500], Loss: 1.0093619097024202\n",
      "Epoch [43/500], Loss: 1.0110333040356636\n",
      "Epoch [44/500], Loss: 1.0078263422474265\n",
      "Epoch [45/500], Loss: 1.0048166075721383\n",
      "Epoch [46/500], Loss: 1.0020629465579987\n",
      "Epoch [47/500], Loss: 0.9997049393132329\n",
      "Epoch [48/500], Loss: 1.0013805301859975\n",
      "Epoch [49/500], Loss: 0.999683721922338\n",
      "Epoch [50/500], Loss: 0.9972415547817945\n",
      "Epoch [50/500], prec: 0.056286549707602336, rec: 0.16885469397905947, f1: 0.08189782201673668\n",
      "Epoch [51/500], Loss: 0.9980256203562021\n",
      "Epoch [52/500], Loss: 0.9977639075368643\n",
      "Epoch [53/500], Loss: 0.9968623658642173\n",
      "Epoch [54/500], Loss: 0.9946092460304499\n",
      "Epoch [55/500], Loss: 0.992016676813364\n",
      "Epoch [56/500], Loss: 0.9913102453574538\n",
      "Epoch [57/500], Loss: 0.9909131526947021\n",
      "Epoch [58/500], Loss: 0.9906431920826435\n",
      "Epoch [59/500], Loss: 0.9919201852753758\n",
      "Epoch [60/500], Loss: 0.988214747980237\n",
      "Epoch [60/500], prec: 0.061737677527151216, rec: 0.1856099486706181, f1: 0.08993150186637425\n",
      "Epoch [61/500], Loss: 0.9878053637221456\n",
      "Epoch [62/500], Loss: 0.98619145154953\n",
      "Epoch [63/500], Loss: 0.9873193269595504\n",
      "Epoch [64/500], Loss: 0.9888897063210607\n",
      "Epoch [65/500], Loss: 0.986978336237371\n",
      "Epoch [66/500], Loss: 0.9860535031184554\n",
      "Epoch [67/500], Loss: 0.984027398750186\n",
      "Epoch [68/500], Loss: 0.9843103876337409\n",
      "Epoch [69/500], Loss: 0.9841153128072619\n",
      "Epoch [70/500], Loss: 0.983623931184411\n",
      "Epoch [70/500], prec: 0.06539264828738514, rec: 0.19663847132263987, f1: 0.09520167652601255\n",
      "Epoch [71/500], Loss: 0.9813498724251986\n",
      "Epoch [72/500], Loss: 0.983402413316071\n",
      "Epoch [73/500], Loss: 0.9811165370047092\n",
      "Epoch [74/500], Loss: 0.9807405648753047\n",
      "Epoch [75/500], Loss: 0.9841536562889814\n",
      "Epoch [76/500], Loss: 0.9818917624652386\n",
      "Epoch [77/500], Loss: 0.9767186213284731\n",
      "Epoch [78/500], Loss: 0.9786533256992698\n",
      "Epoch [79/500], Loss: 0.9791948571801186\n",
      "Epoch [80/500], Loss: 0.9794265870004892\n",
      "Epoch [80/500], prec: 0.06697994987468671, rec: 0.2013485892396075, f1: 0.09749304243121017\n",
      "Epoch [81/500], Loss: 0.9783012149855494\n",
      "Epoch [82/500], Loss: 0.9784237379208207\n",
      "Epoch [83/500], Loss: 0.9806919330731034\n",
      "Epoch [84/500], Loss: 0.9782516751438379\n",
      "Epoch [85/500], Loss: 0.9766158508136868\n",
      "Epoch [86/500], Loss: 0.9782979935407639\n",
      "Epoch [87/500], Loss: 0.9797853836789727\n",
      "Epoch [88/500], Loss: 0.9736875146627426\n",
      "Epoch [89/500], Loss: 0.9752628346905112\n",
      "Epoch [90/500], Loss: 0.9768703514710069\n",
      "Epoch [90/500], prec: 0.06812865497076023, rec: 0.20541971223717806, f1: 0.09926199191495357\n",
      "Epoch [91/500], Loss: 0.9756552176550031\n",
      "Epoch [92/500], Loss: 0.9749902160838246\n",
      "Epoch [93/500], Loss: 0.9722112277522683\n",
      "Epoch [94/500], Loss: 0.9766376102343202\n",
      "Epoch [95/500], Loss: 0.9812672520056367\n",
      "Epoch [96/500], Loss: 0.9783309223130345\n",
      "Epoch [97/500], Loss: 0.9741554521024227\n",
      "Epoch [98/500], Loss: 0.9725468158721924\n",
      "Epoch [99/500], Loss: 0.9744932781904936\n",
      "Epoch [100/500], Loss: 0.9718494601547718\n",
      "Epoch [100/500], prec: 0.06969507101086049, rec: 0.21015286893562588, f1: 0.10159121619037281\n",
      "Epoch [101/500], Loss: 0.9705205233767629\n",
      "Epoch [102/500], Loss: 0.973814987577498\n",
      "Epoch [103/500], Loss: 0.9709980636835098\n",
      "Epoch [104/500], Loss: 0.9754285402595997\n",
      "Epoch [105/500], Loss: 0.9726400626823306\n",
      "Epoch [106/500], Loss: 0.9686976484954357\n",
      "Epoch [107/500], Loss: 0.9742563683539629\n",
      "Epoch [108/500], Loss: 0.9714035140350461\n",
      "Epoch [109/500], Loss: 0.9701527105644345\n",
      "Epoch [110/500], Loss: 0.9705448783934116\n",
      "Epoch [110/500], prec: 0.06911027568922305, rec: 0.2071994630406231, f1: 0.1005146326151744\n",
      "Epoch [111/500], Loss: 0.9710371866822243\n",
      "Epoch [112/500], Loss: 0.968839637003839\n",
      "Epoch [113/500], Loss: 0.9712737426161766\n",
      "Epoch [114/500], Loss: 0.972640692256391\n",
      "Epoch [115/500], Loss: 0.9692091066390276\n",
      "Epoch [116/500], Loss: 0.9698202181607485\n",
      "Epoch [117/500], Loss: 0.9680226342752576\n",
      "Epoch [118/500], Loss: 0.9673465918749571\n",
      "Epoch [119/500], Loss: 0.9693490220233798\n",
      "Epoch [120/500], Loss: 0.9690929464995861\n",
      "Epoch [120/500], prec: 0.07101086048454469, rec: 0.21376591205066509, f1: 0.10346842331762077\n",
      "Epoch [121/500], Loss: 0.9694209741428494\n",
      "Epoch [122/500], Loss: 0.9719161381945014\n",
      "Epoch [123/500], Loss: 0.9747677203267813\n",
      "Epoch [124/500], Loss: 0.9710882045328617\n",
      "Epoch [125/500], Loss: 0.9691272666677833\n",
      "Epoch [126/500], Loss: 0.9681649338454008\n",
      "Epoch [127/500], Loss: 0.9714089808985591\n",
      "Epoch [128/500], Loss: 0.9675474409013987\n",
      "Epoch [129/500], Loss: 0.9651601864024997\n",
      "Epoch [130/500], Loss: 0.9660823363810778\n",
      "Epoch [130/500], prec: 0.06969507101086048, rec: 0.20934401002458383, f1: 0.10150617881919059\n",
      "Epoch [131/500], Loss: 0.9710548967123032\n",
      "Epoch [132/500], Loss: 0.9684942029416561\n",
      "Epoch [133/500], Loss: 0.9672196414321661\n",
      "Epoch [134/500], Loss: 0.9678677497431636\n",
      "Epoch [135/500], Loss: 0.9644355811178684\n",
      "Epoch [136/500], Loss: 0.9670691071078181\n",
      "Epoch [137/500], Loss: 0.9673159774392843\n",
      "Epoch [138/500], Loss: 0.9638340407982469\n",
      "Epoch [139/500], Loss: 0.9692367492243648\n",
      "Epoch [140/500], Loss: 0.9662567060440779\n",
      "Epoch [140/500], prec: 0.06965329991645781, rec: 0.20993397767789176, f1: 0.10148655352683904\n",
      "Epoch [141/500], Loss: 0.9674860825762153\n",
      "Epoch [142/500], Loss: 0.9668355276808143\n",
      "Epoch [143/500], Loss: 0.9664908172562718\n",
      "Epoch [144/500], Loss: 0.9654004303738475\n",
      "Epoch [145/500], Loss: 0.9647859614342451\n",
      "Epoch [146/500], Loss: 0.9697067216038704\n",
      "Epoch [147/500], Loss: 0.9651388023048639\n",
      "Epoch [148/500], Loss: 0.9669803557917476\n",
      "Epoch [149/500], Loss: 0.9646039856597781\n",
      "Epoch [150/500], Loss: 0.9674203665927052\n",
      "Epoch [150/500], prec: 0.07071846282372599, rec: 0.21267892066530739, f1: 0.10300221999933874\n",
      "Epoch [151/500], Loss: 0.9706095224246383\n",
      "Epoch [152/500], Loss: 0.962055885232985\n",
      "Epoch [153/500], Loss: 0.9656960098072886\n",
      "Epoch [154/500], Loss: 0.9653051774948835\n",
      "Epoch [155/500], Loss: 0.9636418465524912\n",
      "Epoch [156/500], Loss: 0.963971690274775\n",
      "Epoch [157/500], Loss: 0.9640740249305964\n",
      "Epoch [158/500], Loss: 0.9632696760818362\n",
      "Epoch [159/500], Loss: 0.961951813660562\n",
      "Epoch [160/500], Loss: 0.9630252756178379\n",
      "Epoch [160/500], prec: 0.07096908939014203, rec: 0.2142082963330314, f1: 0.10347564672488345\n",
      "Epoch [161/500], Loss: 0.9656162355095148\n",
      "Epoch [162/500], Loss: 0.9648655382916331\n",
      "Epoch [163/500], Loss: 0.9632712742313743\n",
      "Epoch [164/500], Loss: 0.9613386793062091\n",
      "Epoch [165/500], Loss: 0.9654212705790997\n",
      "Epoch [166/500], Loss: 0.9648502133786678\n",
      "Epoch [167/500], Loss: 0.9651250140741467\n",
      "Epoch [168/500], Loss: 0.9678109344094992\n",
      "Epoch [169/500], Loss: 0.9607854252681136\n",
      "Epoch [170/500], Loss: 0.9624641723930836\n",
      "Epoch [170/500], prec: 0.07009189640768589, rec: 0.20986925152374822, f1: 0.10192812672651798\n",
      "Epoch [171/500], Loss: 0.9632914792746305\n",
      "Epoch [172/500], Loss: 0.9634014926850796\n",
      "Epoch [173/500], Loss: 0.9649748029187322\n",
      "Epoch [174/500], Loss: 0.9639837425202131\n",
      "Epoch [175/500], Loss: 0.9664416871964931\n",
      "Epoch [176/500], Loss: 0.9615948526188731\n",
      "Epoch [177/500], Loss: 0.961086087860167\n",
      "Epoch [178/500], Loss: 0.9608894679695368\n",
      "Epoch [179/500], Loss: 0.966228392906487\n",
      "Epoch [180/500], Loss: 0.9614587184041739\n",
      "Epoch [180/500], prec: 0.07059314954051796, rec: 0.21182339015210594, f1: 0.10276820873747214\n",
      "Epoch [181/500], Loss: 0.9602600019425154\n",
      "Epoch [182/500], Loss: 0.9624453457072377\n",
      "Epoch [183/500], Loss: 0.9659536927938461\n",
      "Epoch [184/500], Loss: 0.960198599845171\n",
      "Epoch [185/500], Loss: 0.9610946280881763\n",
      "Epoch [186/500], Loss: 0.9638886963948607\n",
      "Epoch [187/500], Loss: 0.967036840505898\n",
      "Epoch [188/500], Loss: 0.961951520293951\n",
      "Epoch [189/500], Loss: 0.9612949015572667\n",
      "Epoch [190/500], Loss: 0.9658494954928756\n",
      "Epoch [190/500], prec: 0.07107351712614869, rec: 0.21335067794231943, f1: 0.10348735643771381\n",
      "Epoch [191/500], Loss: 0.966143955476582\n",
      "Epoch [192/500], Loss: 0.9574124924838543\n",
      "Epoch [193/500], Loss: 0.9621675116941333\n",
      "Epoch [194/500], Loss: 0.9573580389842391\n",
      "Epoch [195/500], Loss: 0.9587556272745132\n",
      "Epoch [196/500], Loss: 0.9612383134663105\n",
      "Epoch [197/500], Loss: 0.9583852728828788\n",
      "Epoch [198/500], Loss: 0.958260677754879\n",
      "Epoch [199/500], Loss: 0.9609885681420565\n",
      "Epoch [200/500], Loss: 0.9622058132663369\n",
      "Epoch [200/500], prec: 0.07055137844611528, rec: 0.21154896929165487, f1: 0.10272618075963338\n",
      "Epoch [201/500], Loss: 0.9593137232586741\n",
      "Epoch [202/500], Loss: 0.961318782530725\n",
      "Epoch [203/500], Loss: 0.9658335605636239\n",
      "Epoch [204/500], Loss: 0.9639475857838988\n",
      "Epoch [205/500], Loss: 0.9608407244086266\n",
      "Epoch [206/500], Loss: 0.9620612198486924\n",
      "Epoch [207/500], Loss: 0.9590488392859697\n",
      "Epoch [208/500], Loss: 0.9594946317374706\n",
      "Epoch [209/500], Loss: 0.9600038258358836\n",
      "Epoch [210/500], Loss: 0.9609979763627052\n",
      "Epoch [210/500], prec: 0.07201336675020888, rec: 0.2158841323797114, f1: 0.10476765231508824\n",
      "Epoch [211/500], Loss: 0.9595456710085273\n",
      "Epoch [212/500], Loss: 0.9620078960433602\n",
      "Epoch [213/500], Loss: 0.9601207338273525\n",
      "Epoch [214/500], Loss: 0.9625739855691791\n",
      "Epoch [215/500], Loss: 0.9594920473173261\n",
      "Epoch [216/500], Loss: 0.9583141738548875\n",
      "Epoch [217/500], Loss: 0.9611793980002403\n",
      "Epoch [218/500], Loss: 0.962254237383604\n",
      "Epoch [219/500], Loss: 0.962378803640604\n",
      "Epoch [220/500], Loss: 0.9598945127800107\n",
      "Epoch [220/500], prec: 0.07182539682539682, rec: 0.2159548853830281, f1: 0.10457806339557225\n",
      "Epoch [221/500], Loss: 0.9585158992558718\n",
      "Epoch [222/500], Loss: 0.9594223657622933\n",
      "Epoch [223/500], Loss: 0.9640928143635392\n",
      "Epoch [224/500], Loss: 0.9620166840031743\n",
      "Epoch [225/500], Loss: 0.958752017468214\n",
      "Epoch [226/500], Loss: 0.9591532442718744\n",
      "Epoch [227/500], Loss: 0.9602433070540428\n",
      "Epoch [228/500], Loss: 0.9639407759532332\n",
      "Epoch [229/500], Loss: 0.9611562713980675\n",
      "Epoch [230/500], Loss: 0.9581676740199327\n",
      "Epoch [230/500], prec: 0.07176274018379282, rec: 0.21575122473815211, f1: 0.10459700648356593\n",
      "Epoch [231/500], Loss: 0.9575360538437963\n",
      "Epoch [232/500], Loss: 0.9604922374710441\n",
      "Epoch [233/500], Loss: 0.9599717883393168\n",
      "Epoch [234/500], Loss: 0.958422633819282\n",
      "Epoch [235/500], Loss: 0.9592921053990722\n",
      "Epoch [236/500], Loss: 0.9595857402309775\n",
      "Epoch [237/500], Loss: 0.9611535696312785\n",
      "Epoch [238/500], Loss: 0.9613545862957835\n",
      "Epoch [239/500], Loss: 0.9627959299832582\n",
      "Epoch [240/500], Loss: 0.9587288051843643\n",
      "Epoch [240/500], prec: 0.07222222222222223, rec: 0.21671043334975734, f1: 0.10516137948747117\n",
      "Epoch [241/500], Loss: 0.9558619158342481\n",
      "Epoch [242/500], Loss: 0.960220068693161\n",
      "Epoch [243/500], Loss: 0.9595994772389531\n",
      "Epoch [244/500], Loss: 0.9586011366918683\n",
      "Epoch [245/500], Loss: 0.957838817499578\n",
      "Epoch [246/500], Loss: 0.9597595306113362\n",
      "Epoch [247/500], Loss: 0.9587533939629793\n",
      "Epoch [248/500], Loss: 0.965146292001009\n",
      "Epoch [249/500], Loss: 0.9586537247523665\n",
      "Epoch [250/500], Loss: 0.9583635730668902\n",
      "Epoch [250/500], prec: 0.07215956558061822, rec: 0.21662626247387248, f1: 0.10501849775859905\n",
      "Epoch [251/500], Loss: 0.9577051606029272\n",
      "Epoch [252/500], Loss: 0.959746964275837\n",
      "Epoch [253/500], Loss: 9.861437405459583\n",
      "Epoch [254/500], Loss: 16.60267634689808\n",
      "Epoch [255/500], Loss: 16.59984539449215\n",
      "Epoch [256/500], Loss: 16.58002896606922\n",
      "Epoch [257/500], Loss: 16.61966186761856\n",
      "Epoch [258/500], Loss: 16.585690796375275\n",
      "Epoch [259/500], Loss: 16.57531076669693\n",
      "Epoch [260/500], Loss: 16.59040905535221\n",
      "Epoch [260/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [261/500], Loss: 16.61494368314743\n",
      "Epoch [262/500], Loss: 16.58663445711136\n",
      "Epoch [263/500], Loss: 16.577198028564453\n",
      "Epoch [264/500], Loss: 16.568705290555954\n",
      "Epoch [265/500], Loss: 16.57908533513546\n",
      "Epoch [266/500], Loss: 16.601732775568962\n",
      "Epoch [267/500], Loss: 16.59040902554989\n",
      "Epoch [268/500], Loss: 16.5620998442173\n",
      "Epoch [269/500], Loss: 16.593239918351173\n",
      "Epoch [270/500], Loss: 16.59701456129551\n",
      "Epoch [270/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [271/500], Loss: 16.577198058366776\n",
      "Epoch [272/500], Loss: 16.596070900559425\n",
      "Epoch [273/500], Loss: 16.58191630244255\n",
      "Epoch [274/500], Loss: 16.59135267138481\n",
      "Epoch [275/500], Loss: 16.579085424542427\n",
      "Epoch [276/500], Loss: 16.59890177845955\n",
      "Epoch [277/500], Loss: 16.59135265648365\n",
      "Epoch [278/500], Loss: 16.607394516468048\n",
      "Epoch [279/500], Loss: 16.597958132624626\n",
      "Epoch [280/500], Loss: 16.597958132624626\n",
      "Epoch [280/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [281/500], Loss: 16.59607082605362\n",
      "Epoch [282/500], Loss: 16.580972611904144\n",
      "Epoch [283/500], Loss: 16.59040905535221\n",
      "Epoch [284/500], Loss: 16.63664737343788\n",
      "Epoch [285/500], Loss: 16.59890179336071\n",
      "Epoch [286/500], Loss: 16.621549174189568\n",
      "Epoch [287/500], Loss: 16.582859873771667\n",
      "Epoch [288/500], Loss: 16.573423475027084\n",
      "Epoch [289/500], Loss: 16.58285991847515\n",
      "Epoch [290/500], Loss: 16.592296198010445\n",
      "Epoch [290/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [291/500], Loss: 16.58663436770439\n",
      "Epoch [292/500], Loss: 16.58757807314396\n",
      "Epoch [293/500], Loss: 16.582859948277473\n",
      "Epoch [294/500], Loss: 16.59512721002102\n",
      "Epoch [295/500], Loss: 16.584747195243835\n",
      "Epoch [296/500], Loss: 16.56587441265583\n",
      "Epoch [297/500], Loss: 16.577198058366776\n",
      "Epoch [298/500], Loss: 16.564930737018585\n",
      "Epoch [299/500], Loss: 16.574367105960846\n",
      "Epoch [300/500], Loss: 16.564930766820908\n",
      "Epoch [300/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [301/500], Loss: 16.58002895116806\n",
      "Epoch [302/500], Loss: 16.593239903450012\n",
      "Epoch [303/500], Loss: 16.593239933252335\n",
      "Epoch [304/500], Loss: 16.57342341542244\n",
      "Epoch [305/500], Loss: 16.57153621315956\n",
      "Epoch [306/500], Loss: 16.569648921489716\n",
      "Epoch [307/500], Loss: 16.62343642115593\n",
      "Epoch [308/500], Loss: 16.59795817732811\n",
      "Epoch [309/500], Loss: 16.58285990357399\n",
      "Epoch [310/500], Loss: 16.582859858870506\n",
      "Epoch [310/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [311/500], Loss: 16.57908543944359\n",
      "Epoch [312/500], Loss: 16.614943653345108\n",
      "Epoch [313/500], Loss: 16.600789055228233\n",
      "Epoch [314/500], Loss: 16.57625436782837\n",
      "Epoch [315/500], Loss: 16.585690796375275\n",
      "Epoch [316/500], Loss: 16.588521748781204\n",
      "Epoch [317/500], Loss: 16.601732715964317\n",
      "Epoch [318/500], Loss: 16.57719810307026\n",
      "Epoch [319/500], Loss: 16.588521718978882\n",
      "Epoch [320/500], Loss: 16.623436465859413\n",
      "Epoch [320/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [321/500], Loss: 16.610225468873978\n",
      "Epoch [322/500], Loss: 16.603620007634163\n",
      "Epoch [323/500], Loss: 16.590408995747566\n",
      "Epoch [324/500], Loss: 16.57719810307026\n",
      "Epoch [325/500], Loss: 16.566818058490753\n",
      "Epoch [326/500], Loss: 16.60173274576664\n",
      "Epoch [327/500], Loss: 16.592296302318573\n",
      "Epoch [328/500], Loss: 16.57908533513546\n",
      "Epoch [329/500], Loss: 16.585690796375275\n",
      "Epoch [330/500], Loss: 16.572479873895645\n",
      "Epoch [330/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [331/500], Loss: 16.563987135887146\n",
      "Epoch [332/500], Loss: 16.634760156273842\n",
      "Epoch [333/500], Loss: 16.58191628754139\n",
      "Epoch [334/500], Loss: 16.584747165441513\n",
      "Epoch [335/500], Loss: 16.60550731420517\n",
      "Epoch [336/500], Loss: 16.59135264158249\n",
      "Epoch [337/500], Loss: 16.58002896606922\n",
      "Epoch [338/500], Loss: 16.620605558156967\n",
      "Epoch [339/500], Loss: 16.623436450958252\n",
      "Epoch [340/500], Loss: 16.610225439071655\n",
      "Epoch [340/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [341/500], Loss: 16.593239948153496\n",
      "Epoch [342/500], Loss: 16.582859948277473\n",
      "Epoch [343/500], Loss: 16.600789114832878\n",
      "Epoch [344/500], Loss: 16.58191627264023\n",
      "Epoch [345/500], Loss: 16.59229625761509\n",
      "Epoch [346/500], Loss: 16.600789070129395\n",
      "Epoch [347/500], Loss: 16.607394590973854\n",
      "Epoch [348/500], Loss: 16.59890180826187\n",
      "Epoch [349/500], Loss: 16.596070930361748\n",
      "Epoch [350/500], Loss: 16.581916242837906\n",
      "Epoch [350/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [351/500], Loss: 16.59229639172554\n",
      "Epoch [352/500], Loss: 16.565874338150024\n",
      "Epoch [353/500], Loss: 16.59512722492218\n",
      "Epoch [354/500], Loss: 16.63853468000889\n",
      "Epoch [355/500], Loss: 16.584747195243835\n",
      "Epoch [356/500], Loss: 16.59984542429447\n",
      "Epoch [357/500], Loss: 16.58474712073803\n",
      "Epoch [358/500], Loss: 16.623436525464058\n",
      "Epoch [359/500], Loss: 16.585690826177597\n",
      "Epoch [360/500], Loss: 16.570592537522316\n",
      "Epoch [360/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [361/500], Loss: 16.598901867866516\n",
      "Epoch [362/500], Loss: 16.61871825158596\n",
      "Epoch [363/500], Loss: 16.57059259712696\n",
      "Epoch [364/500], Loss: 16.593239918351173\n",
      "Epoch [365/500], Loss: 16.605507358908653\n",
      "Epoch [366/500], Loss: 16.602676331996918\n",
      "Epoch [367/500], Loss: 16.609281808137894\n",
      "Epoch [368/500], Loss: 16.577198043465614\n",
      "Epoch [369/500], Loss: 16.579085275530815\n",
      "Epoch [370/500], Loss: 16.613056376576424\n",
      "Epoch [370/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [371/500], Loss: 16.632872849702835\n",
      "Epoch [372/500], Loss: 16.581916227936745\n",
      "Epoch [373/500], Loss: 16.602676436305046\n",
      "Epoch [374/500], Loss: 16.587578117847443\n",
      "Epoch [375/500], Loss: 16.596070870757103\n",
      "Epoch [376/500], Loss: 16.577198058366776\n",
      "Epoch [377/500], Loss: 16.580972656607628\n",
      "Epoch [378/500], Loss: 16.572479873895645\n",
      "Epoch [379/500], Loss: 16.580972597002983\n",
      "Epoch [380/500], Loss: 16.597014501690865\n",
      "Epoch [380/500], prec: 0.0016499582289055976, rec: 0.004960578799351934, f1: 0.0023826293248227675\n",
      "Epoch [381/500], Loss: 16.57531076669693\n",
      "Epoch [382/500], Loss: 16.601732715964317\n",
      "Epoch [383/500], Loss: 16.587578117847443\n",
      "Epoch [384/500], Loss: 16.59418362379074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(prediction , label)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization step\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\dangkh\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\dangkh\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model, optimizer, and loss function\n",
    "\n",
    "mp, mr, mf = 0, 0, 0\n",
    "print(model)\n",
    "# stop\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay= 1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_idx, batchDat in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, label = batchDat\n",
    "        userDat = data.to(device)\n",
    "        label = label.to(device)\n",
    "        restDat = rest_feature\n",
    "        prediction = model(userDat, restDat)\n",
    "        loss = criterion(prediction , label)\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() \n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss}')\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        lResults = evaluateModel(model, test_loader, rest_feature, gt, test_users, 20, rest_Label)\n",
    "        p, r, f = extractResult(lResults)\n",
    "        if mean(r) > mean(mr):\n",
    "            mp, mr, mf = p, r, f\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], prec: {mean(p)}, rec: {mean(r)}, f1: {mean(f)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a922fc4-ea1d-4231-aba2-a68bc7fdefd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07222222222222223 0.21671043334975734 0.10516137948747117\n"
     ]
    }
   ],
   "source": [
    "p, r, f = mp, mr, mf \n",
    "print(mean(p), mean(r), mean(f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
